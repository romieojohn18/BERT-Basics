{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT BASICS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVfX0gySiFgK"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKaGCzpHi7XP"
      },
      "source": [
        "# Practical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF3VCjt8jHKI"
      },
      "source": [
        "## Downloading Required Files\n",
        "- `tensorflow_hub` - Repository for all trained model for use cases\n",
        "- `tensorflow_text` - TF.Text is a TensorFlow library of text related ops, modules, and subgraphs. The library can perform the preprocessing regularly required by text-based models, and includes other features useful for sequence modeling not provided by core TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQJPL0PYi2Wc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6576ef-1a5d-49c1-824d-f4fe28f4e032"
      },
      "source": [
        "!pip install tensorflow-text"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (2.6.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (2.6.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (2.6.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (1.39.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (1.12.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (0.37.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (2.6.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (5.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow-text) (3.7.4.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.7,>=2.6.0->tensorflow-text) (1.5.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (1.34.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (0.4.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow-text) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igxK6RmpiEaH"
      },
      "source": [
        "# importing libraries\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7G5amEWjvDc"
      },
      "source": [
        "## Setting the downloading path url\n",
        "- For Preprocessor\n",
        "- For Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_REEWGkzj42Y"
      },
      "source": [
        "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R8CTnUxkdwI"
      },
      "source": [
        "## Creating Preprocessing Objects\n",
        "- Use hub layers to achive it as it makes the object as a function pointer , where one can pass some values\n",
        "- bert_preprocess : preprocessing text, , returns a dictionart object\n",
        "- test_text : - text which we will pass to bert_preprocess() to get the preprocessed text\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwCgTAVXkn0f"
      },
      "source": [
        "# creating hub layers\n",
        "bert_preprocess_model = hub.KerasLayer(preprocess_url)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzm3tTa8nKF1"
      },
      "source": [
        "# creating testing text\n",
        "test_text = ['I love pizza', 'India is my country', 'Italy is fun place to visit']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvw_ZPEYnrK_",
        "outputId": "50de6075-c02a-4757-9140-564e1000ac7d"
      },
      "source": [
        "# preprocessing text\n",
        "text_preprocessed = bert_preprocess_model(test_text)\n",
        "text_preprocessed.keys()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_type_ids', 'input_word_ids', 'input_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ujPKT5IoC2L"
      },
      "source": [
        "## Understanding Preprocessed Dictonary Keys\n",
        "\n",
        "- input_mask\n",
        "- input_type_ids\n",
        "- input_words_ids\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vyp5vIuYWui"
      },
      "source": [
        "### Input Mask\n",
        "\n",
        "- A mask of the words in a sentence - all masks starts with `CLF` token and `SEP` token\n",
        "- So the masked array is `sentence size + 2`\n",
        "- The token is defined for CLF - 101 and SEP - 102\n",
        "- Tensor shape - (no of sentence, 128- maximum length of sentence- other padded with zeors as no values present)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiV7wZlnoBhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef5abd91-86be-47ed-8759-5266c5572b6a"
      },
      "source": [
        "# input_mask \n",
        "text_preprocessed['input_mask']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 128), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb7yT1oTaUlg"
      },
      "source": [
        "### Input Type Ids\n",
        "- Give id's to multiple sentences in one statement\n",
        "- Usefull for same secnario\n",
        "- Not usefull in our case\n",
        "- Help in contextiualizing the sentence\n",
        "- Usefull for a object like pandas data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMWW6aNqZHT6",
        "outputId": "e31cf594-321d-44ad-a6d0-a18671b6cf42"
      },
      "source": [
        "# input_type_ids\n",
        "text_preprocessed['input_type_ids']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 128), dtype=int32, numpy=\n",
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb01Ok7vcOEx"
      },
      "source": [
        "### Input Word Id's\n",
        "\n",
        "- has the token ids of the input sequences.\n",
        "- Give unique id's for indivisual words\n",
        "- Each word in encoded(ids can be from a vocabulary) , padded and seperated\n",
        "- Length : (no of sentence , 128-max length of each sentence)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoYSoM78bACr",
        "outputId": "94765f57-85d8-46f5-f90b-2bc5b05ae37b"
      },
      "source": [
        "# input_word_ids\n",
        "text_preprocessed['input_word_ids']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 128), dtype=int32, numpy=\n",
              "array([[  101,  1045,  2293, 10733,   102,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [  101,  2634,  2003,  2026,  2406,   102,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [  101,  3304,  2003,  4569,  2173,  2000,  3942,   102,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgsLELgKdhA7"
      },
      "source": [
        "## Creating Embeddings\n",
        "\n",
        "- Embeddings are unique repersentation of wordsin from of numbers\n",
        "\n",
        "- In word 2 vec , similar words are given same embedding id's , i.e even for a diffferent secnario it will predict the same words if it had to do so.\n",
        "\n",
        "- BERT - `Bidirectional Encoder Repersentation From Transformer` solves this issue by creating a contextulized embedding.\n",
        "\n",
        "\n",
        "USAGE: \n",
        "- WORD EMBEDDINGS GENERATION : for each time stamp of a given words , it also carry some attention or semantics of previous words(inf forms of feature vectors )/ look into other parts of sentence, allow us to predict words unbiasedly and create goood embedding vectors.\n",
        "\n",
        "- CLASSIFICATION:  It allows us to do parallel computation which speeds up the calculations and thus capturing the meaning of a word in a right way as it can now see the whole sentence in one go and predict out words with high probability values. \n",
        "\n",
        "- WORDS/ SENTENCES PREDICTIONS: Since the previous predection is feed into it and due to above feature , it can also genrate new word suggestion or even sentences - similar to auto complete.\n",
        "\n",
        "\n",
        "STEPS INVOLVED\n",
        "- Create a encoder/ model object using hub API - to act as a function pointer\n",
        "- Pass `prerpocessed_text` into model - important\n",
        "- Check the keys.\n",
        "- Reuturns a dictonary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI62wvKcdSxT"
      },
      "source": [
        "# create our model- encoder which encodes to create word embeddings\n",
        "bert_encoder_model = hub.KerasLayer(encoder_url)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r2xjHczhjI0"
      },
      "source": [
        "# encoding - creating embeddings\n",
        "bert_results = bert_encoder_model(text_preprocessed)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOVKlX5KhzT1",
        "outputId": "522f47b7-b314-4bc8-833e-d12ea243fe39"
      },
      "source": [
        "# check the keys\n",
        "bert_results.keys()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['default', 'pooled_output', 'sequence_output', 'encoder_outputs'])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-GLsTYfijvl"
      },
      "source": [
        "## Understanding Embedding Dictonary\n",
        "\n",
        "- pooled_output\n",
        "- sequence_output\n",
        "- encoder_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKxPSIW4jhvQ"
      },
      "source": [
        "### Pooled Output\n",
        "- Embedding for the entire sentence\n",
        "- Length : `(no of sentence, no of hidden units - 768[this case])` \n",
        "- Also these 768 will not be 0 as bert carries some of the contextual meaning for each meaning i.e relates how much one feature differ from each other [-ve less relatable , +ve - very relatable], this is the feature why bert is so popular and powerful in NLP task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE1BwHXGib_g",
        "outputId": "d5505678-055f-40a9-ebb3-da3d980a2030"
      },
      "source": [
        "# pooled_output\n",
        "bert_results['pooled_output']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 768), dtype=float32, numpy=\n",
              "array([[-0.8258812 , -0.23015198,  0.44445884, ...,  0.364323  ,\n",
              "        -0.6134957 ,  0.88324934],\n",
              "       [-0.86772424, -0.396556  , -0.3774799 , ..., -0.11730427,\n",
              "        -0.6479708 ,  0.89818156],\n",
              "       [-0.73642206, -0.19927329,  0.39546844, ...,  0.17739205,\n",
              "        -0.57021993,  0.7637285 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_ta_EIklB2P"
      },
      "source": [
        "### Sequence output\n",
        "\n",
        "- This is the repersentation/ embedding  of indivisual word of a sentence\n",
        "- Due to processing sentence become a length of 128\n",
        "- Hidden state is 768\n",
        "- No of sentence \n",
        "\n",
        "So length of the sequnence out put array/ tensor is `(no of sentences, length of sentence-128, no of hidden units -768 )`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v__WrlxzkcDV",
        "outputId": "1443045b-5033-4c78-bcd5-544539537bd4"
      },
      "source": [
        "# sequence_output\n",
        "bert_results['sequence_output']"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              "array([[[ 0.13989685,  0.30410853,  0.06352295, ..., -0.10268749,\n",
              "          0.22148427,  0.14977898],\n",
              "        [ 0.32137358,  0.29354602, -0.1408123 , ..., -0.20841433,\n",
              "          0.83567744,  0.20442402],\n",
              "        [ 1.1886755 ,  0.64992356,  0.6742487 , ...,  0.10617819,\n",
              "          0.41522282, -0.23921698],\n",
              "        ...,\n",
              "        [ 0.2002529 ,  0.27129635,  0.45000356, ...,  0.22973916,\n",
              "          0.02177444,  0.11564779],\n",
              "        [ 0.1203473 ,  0.17267032,  0.36960474, ...,  0.27761802,\n",
              "          0.02981692,  0.06090191],\n",
              "        [-0.23403423, -0.10138148,  0.3471217 , ...,  0.44735333,\n",
              "          0.04013262, -0.04988689]],\n",
              "\n",
              "       [[-0.02354308,  0.37282205, -0.09210153, ..., -0.44056374,\n",
              "          0.01131827,  0.3328247 ],\n",
              "        [-0.6194298 , -0.28675115, -0.72419006, ..., -0.38319874,\n",
              "          0.31782746, -0.2673164 ],\n",
              "        [ 0.22914922, -0.26078117, -0.25905174, ..., -0.38670355,\n",
              "          0.53242093,  0.7462712 ],\n",
              "        ...,\n",
              "        [ 0.03039839,  0.0043057 ,  0.3688119 , ..., -0.07569657,\n",
              "         -0.14002268, -0.04536304],\n",
              "        [-0.04000736, -0.0164677 ,  0.41010898, ..., -0.04975221,\n",
              "         -0.144483  , -0.07688889],\n",
              "        [ 0.02779413, -0.08786289,  0.40672043, ..., -0.01367262,\n",
              "         -0.15657677, -0.11102572]],\n",
              "\n",
              "       [[ 0.22074004,  0.01413434,  0.06443717, ..., -0.17645836,\n",
              "          0.19920635,  0.19690731],\n",
              "        [-0.14704725, -0.54524827, -0.10819175, ..., -0.8173358 ,\n",
              "          0.23186494,  0.19307591],\n",
              "        [-0.05048935, -0.71603614, -0.00176273, ..., -0.4684802 ,\n",
              "          0.04761183, -0.22504431],\n",
              "        ...,\n",
              "        [ 0.01195151, -0.22026901,  0.3875025 , ..., -0.32334277,\n",
              "          0.1346083 ,  0.17516093],\n",
              "        [-0.14100374, -0.20604482,  0.2578193 , ..., -0.16094595,\n",
              "          0.04925277,  0.24305022],\n",
              "        [-0.06052952, -0.22084403,  0.3242475 , ..., -0.06742799,\n",
              "          0.0959111 ,  0.17549217]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLxDz39kmDvO"
      },
      "source": [
        "### Encoder Output\n",
        "\n",
        "- It is the intermediate activations of transformer block and its last encoding is similar to sequence outputs.\n",
        "\n",
        "- Length same as sequence output - `(no of sentences, length of each sentence- 128, no of hidden units-768)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ApkMytSmAbc",
        "outputId": "0415d8c2-90fc-469e-a3c2-e462d8d39b39"
      },
      "source": [
        "# encoder_output\n",
        "bert_results['encoder_outputs']"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              " array([[[ 0.17126326,  0.05714692, -0.0674366 , ...,  0.01732911,\n",
              "           0.14355004,  0.04887236],\n",
              "         [ 0.63244945,  1.2133186 , -0.05207317, ...,  0.5324665 ,\n",
              "           0.8438143 ,  0.26414844],\n",
              "         [ 1.3925557 ,  0.6356847 ,  0.7422873 , ...,  0.4379002 ,\n",
              "           0.93434745,  0.0773314 ],\n",
              "         ...,\n",
              "         [-0.05122608, -0.17709947,  0.735608  , ...,  0.41847372,\n",
              "          -0.19071554,  0.02412996],\n",
              "         [-0.15421638, -0.21907634,  0.5903027 , ...,  0.48437566,\n",
              "          -0.10654722, -0.06792136],\n",
              "         [-0.02584023, -0.14862329,  0.59410834, ...,  0.7565186 ,\n",
              "          -0.3872101 , -0.13480763]],\n",
              " \n",
              "        [[ 0.15777123,  0.04426716, -0.13644354, ..., -0.00874431,\n",
              "           0.12490405,  0.09001191],\n",
              "         [-0.18299678,  0.27142665, -0.63025737, ..., -0.63325226,\n",
              "           0.11569571,  0.18398017],\n",
              "         [-0.7387831 , -0.22359407, -0.29233336, ...,  0.04634879,\n",
              "           0.6207118 ,  0.3838926 ],\n",
              "         ...,\n",
              "         [ 0.13647637, -0.2627006 ,  0.7206661 , ...,  0.17608903,\n",
              "          -0.09332648,  0.20028053],\n",
              "         [ 0.05219504, -0.2700914 ,  0.5672356 , ...,  0.1918603 ,\n",
              "           0.0198402 ,  0.09943388],\n",
              "         [ 0.2545892 , -0.18246709,  0.6072722 , ...,  0.56187636,\n",
              "          -0.34796587,  0.01064491]],\n",
              " \n",
              "        [[ 0.12843443,  0.06256267, -0.02398977, ...,  0.02614059,\n",
              "           0.10695012,  0.06767084],\n",
              "         [-0.5305613 ,  0.7519103 ,  0.16989045, ...,  0.01566395,\n",
              "          -0.6979487 ,  0.30962366],\n",
              "         [-1.0056285 , -0.17192256,  0.01070053, ...,  0.28716633,\n",
              "           0.3490474 ,  0.4487632 ],\n",
              "         ...,\n",
              "         [-0.01171611, -0.18401977,  0.76302165, ...,  0.5255786 ,\n",
              "          -0.2692391 ,  0.10974032],\n",
              "         [-0.12069704, -0.20226324,  0.6311182 , ...,  0.54957396,\n",
              "          -0.18612076,  0.0196421 ],\n",
              "         [ 0.03589962, -0.13956793,  0.6733143 , ...,  0.8733339 ,\n",
              "          -0.50263023, -0.04787347]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              " array([[[ 2.51200572e-02, -1.75340027e-01, -1.46998733e-01, ...,\n",
              "           8.96847397e-02,  1.14558905e-01,  1.07718468e-01],\n",
              "         [ 4.70781446e-01,  1.09189355e+00,  4.00565296e-01, ...,\n",
              "           5.45752466e-01,  2.49515295e-01,  4.72856648e-02],\n",
              "         [ 2.09972167e+00,  9.78228092e-01,  1.24919713e+00, ...,\n",
              "           7.88869441e-01,  4.57188189e-01, -5.72726503e-02],\n",
              "         ...,\n",
              "         [-2.82447845e-01, -1.19807169e-01,  7.95022130e-01, ...,\n",
              "           8.60488653e-01, -4.99546260e-01, -1.99169040e-01],\n",
              "         [-3.31744671e-01, -5.51769808e-02,  6.78519011e-01, ...,\n",
              "           9.27768230e-01, -4.23308045e-01, -2.45877191e-01],\n",
              "         [-3.31965625e-01, -4.30774651e-02,  5.47684252e-01, ...,\n",
              "           1.09798157e+00, -5.43233931e-01, -2.41933405e-01]],\n",
              " \n",
              "        [[ 8.14856961e-02, -1.90999299e-01, -1.73533738e-01, ...,\n",
              "           8.14727694e-02,  1.91468403e-01,  1.07158884e-01],\n",
              "         [-2.74161696e-01,  7.21745491e-01, -5.79899490e-01, ...,\n",
              "          -4.97957647e-01,  5.28280079e-01, -1.02079988e-01],\n",
              "         [-5.72640598e-01, -1.31221294e-01,  8.50296840e-02, ...,\n",
              "          -1.20297186e-01,  5.87652266e-01,  3.74362856e-01],\n",
              "         ...,\n",
              "         [ 4.85898517e-02, -2.24751756e-01,  6.96387410e-01, ...,\n",
              "           8.50378871e-01, -3.66913497e-01, -5.95672391e-02],\n",
              "         [-1.98333338e-03, -1.30663440e-01,  6.81405067e-01, ...,\n",
              "           8.48278284e-01, -3.09227467e-01, -1.11778095e-01],\n",
              "         [ 1.60181075e-01, -1.56818733e-01,  6.09384537e-01, ...,\n",
              "           1.09201753e+00, -5.41365445e-01, -1.82661384e-01]],\n",
              " \n",
              "        [[ 1.15952268e-02, -1.53578997e-01, -1.98014051e-01, ...,\n",
              "           2.38845050e-01,  1.23389795e-01, -1.92736089e-03],\n",
              "         [-7.18920588e-01,  9.26283538e-01,  1.11205012e-01, ...,\n",
              "           2.31291577e-01, -8.94474387e-01, -7.78805278e-03],\n",
              "         [-7.24434316e-01,  5.60068339e-02,  2.96304375e-01, ...,\n",
              "           1.37798473e-01,  8.58645365e-02,  4.77970332e-01],\n",
              "         ...,\n",
              "         [-7.78997764e-02, -2.46661931e-01,  6.80052221e-01, ...,\n",
              "           1.19239056e+00, -5.18218935e-01, -9.84719470e-02],\n",
              "         [-1.87779441e-01, -9.23407897e-02,  7.21029401e-01, ...,\n",
              "           1.12454188e+00, -5.51012278e-01, -1.14089504e-01],\n",
              "         [-6.89840689e-02, -2.15528309e-01,  6.76283717e-01, ...,\n",
              "           1.33384669e+00, -7.23523438e-01, -2.16207176e-01]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              " array([[[ 0.06220839, -0.29466745, -0.0932858 , ...,  0.24601808,\n",
              "           0.03738514,  0.2477464 ],\n",
              "         [ 0.67638606,  0.5469234 ,  0.7000547 , ...,  0.83951694,\n",
              "          -0.0749063 , -0.08132847],\n",
              "         [ 2.7595825 ,  0.4518538 ,  1.5390264 , ...,  0.36351988,\n",
              "           0.09102319, -0.22479813],\n",
              "         ...,\n",
              "         [-0.16043545, -0.07183865,  0.9726825 , ...,  0.9818481 ,\n",
              "          -0.16955966, -0.33260986],\n",
              "         [-0.21813732, -0.02801859,  0.85981584, ...,  0.97875893,\n",
              "          -0.21061298, -0.45523217],\n",
              "         [-0.33493015, -0.08441038,  0.8498106 , ...,  1.1925212 ,\n",
              "          -0.3952245 , -0.45863733]],\n",
              " \n",
              "        [[ 0.04409536, -0.28827643,  0.02449029, ...,  0.22303388,\n",
              "           0.12324256,  0.24995075],\n",
              "         [-0.54428554,  0.39563352, -0.10584646, ..., -0.6607845 ,\n",
              "          -0.01645332, -0.22000559],\n",
              "         [-0.5722246 , -0.2802452 ,  0.28779835, ..., -0.16239452,\n",
              "           0.59959596,  0.58678246],\n",
              "         ...,\n",
              "         [ 0.01214255, -0.18502188,  0.89846826, ...,  0.90672284,\n",
              "           0.02870383, -0.20929736],\n",
              "         [-0.08263579, -0.08786289,  0.82637036, ...,  0.9637913 ,\n",
              "           0.08241004, -0.26967588],\n",
              "         [ 0.05173992, -0.17136255,  0.86307776, ...,  1.1129819 ,\n",
              "          -0.16598618, -0.31493104]],\n",
              " \n",
              "        [[ 0.05575366, -0.23234409, -0.07091793, ...,  0.25406098,\n",
              "           0.12729616,  0.12351875],\n",
              "         [-0.46576083,  0.4440385 ,  0.39320427, ..., -0.12229849,\n",
              "          -1.1773463 , -0.10173389],\n",
              "         [-0.5461948 , -0.11684456,  0.22070529, ..., -0.10514636,\n",
              "          -0.12342911,  0.6790661 ],\n",
              "         ...,\n",
              "         [ 0.0208044 , -0.13747177,  0.86294705, ...,  1.1147883 ,\n",
              "          -0.02936738, -0.13429163],\n",
              "         [-0.14127113,  0.03162674,  0.79942405, ...,  1.1062058 ,\n",
              "          -0.08576041, -0.11942285],\n",
              "         [-0.05224121, -0.13346587,  0.8333315 , ...,  1.2199016 ,\n",
              "          -0.28857738, -0.20132098]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              " array([[[ 0.27347893, -0.4058383 , -0.56801677, ...,  0.40333802,\n",
              "          -0.08019722,  0.5380617 ],\n",
              "         [ 0.8753659 ,  0.27705225,  0.76754326, ...,  0.8390442 ,\n",
              "          -0.18542519, -0.48419797],\n",
              "         [ 2.900644  ,  0.2809408 ,  0.90566826, ...,  0.45749512,\n",
              "          -0.39283586,  0.12870705],\n",
              "         ...,\n",
              "         [-0.3127432 , -0.41014615,  1.1505423 , ...,  0.8895105 ,\n",
              "          -0.5603501 , -0.29110956],\n",
              "         [-0.3359176 , -0.34853998,  0.9789437 , ...,  0.9088255 ,\n",
              "          -0.5724789 , -0.4264249 ],\n",
              "         [-0.62648535, -0.5182022 ,  1.0323361 , ...,  1.1956364 ,\n",
              "          -0.7110686 , -0.33370185]],\n",
              " \n",
              "        [[ 0.23616418, -0.64149004, -0.564929  , ...,  0.56766635,\n",
              "           0.2191039 ,  0.7680185 ],\n",
              "         [-0.6497684 ,  0.6527506 , -0.00804625, ..., -0.22275168,\n",
              "          -0.2076651 , -0.37997782],\n",
              "         [-0.36454806, -0.34749335, -0.22844487, ..., -0.09970941,\n",
              "           0.0096026 ,  1.2130197 ],\n",
              "         ...,\n",
              "         [-0.12376554, -0.5836812 ,  1.1298367 , ...,  0.8480831 ,\n",
              "          -0.74044573, -0.11600235],\n",
              "         [-0.30060443, -0.43751103,  0.99242073, ...,  0.84572715,\n",
              "          -0.65863895, -0.23853502],\n",
              "         [-0.08559977, -0.6021418 ,  1.1593926 , ...,  1.0941261 ,\n",
              "          -0.8195086 , -0.29609984]],\n",
              " \n",
              "        [[ 0.41396806, -0.5264951 , -0.64542437, ...,  0.34373358,\n",
              "           0.34656858,  0.61076   ],\n",
              "         [-0.6530613 ,  0.39239687, -0.19227973, ...,  0.24724127,\n",
              "          -1.354403  , -0.07753248],\n",
              "         [-0.56444013, -0.53905094, -0.2895046 , ...,  0.06996962,\n",
              "          -0.26980796,  0.7950713 ],\n",
              "         ...,\n",
              "         [-0.13584736, -0.6974864 ,  1.026375  , ...,  0.83859766,\n",
              "          -0.6363432 ,  0.07746542],\n",
              "         [-0.31036544, -0.51493365,  0.97371644, ...,  0.88151205,\n",
              "          -0.6572396 ,  0.11982051],\n",
              "         [-0.22307819, -0.76088727,  1.1309563 , ...,  1.1043824 ,\n",
              "          -0.7360754 , -0.06708704]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              " array([[[ 0.21773824, -0.4051019 , -0.5913505 , ...,  0.00728365,\n",
              "          -0.01593059,  0.5643024 ],\n",
              "         [ 1.07377   , -0.28953034,  0.35067895, ...,  0.5364613 ,\n",
              "           0.20441787, -0.32812196],\n",
              "         [ 2.763916  ,  0.5026705 ,  0.40223688, ...,  0.5092604 ,\n",
              "          -0.7674495 ,  0.20983052],\n",
              "         ...,\n",
              "         [ 0.06750894, -0.15271617,  1.1481059 , ...,  0.6670796 ,\n",
              "          -0.1904497 , -0.43765688],\n",
              "         [ 0.05717988, -0.09279571,  1.0511278 , ...,  0.8278275 ,\n",
              "          -0.27492467, -0.5290308 ],\n",
              "         [-0.46349856, -0.19102284,  1.248864  , ...,  1.0400405 ,\n",
              "          -0.42907107, -0.52770174]],\n",
              " \n",
              "        [[-0.04649691, -0.38854122, -0.4831597 , ..., -0.02995366,\n",
              "           0.40223324,  0.7622    ],\n",
              "         [-0.61944324,  0.39600465,  0.19116539, ..., -0.40710062,\n",
              "          -0.23525155, -0.28668445],\n",
              "         [-0.1314937 , -0.54440826, -0.04963275, ..., -0.2461493 ,\n",
              "           0.31289932,  0.7174961 ],\n",
              "         ...,\n",
              "         [-0.01946491, -0.4138579 ,  0.91643167, ..., -0.0077009 ,\n",
              "          -0.40797457, -0.3567729 ],\n",
              "         [-0.16465865, -0.24460727,  0.8954273 , ...,  0.05075268,\n",
              "          -0.4483348 , -0.5021509 ],\n",
              "         [ 0.01934154, -0.5168712 ,  1.0084537 , ...,  0.44982442,\n",
              "          -0.53928345, -0.58997536]],\n",
              " \n",
              "        [[ 0.18245491, -0.47981423, -0.5596692 , ..., -0.03005581,\n",
              "           0.31305528,  0.61831355],\n",
              "         [-0.5590636 ,  0.09195443, -0.24609242, ..., -0.13180104,\n",
              "          -1.4601309 , -0.02463946],\n",
              "         [-0.1923426 , -0.69321245, -0.16398476, ..., -0.06995505,\n",
              "          -0.16767128,  0.505781  ],\n",
              "         ...,\n",
              "         [-0.09670655, -0.48882627,  0.8383848 , ...,  0.21314454,\n",
              "          -0.6323189 , -0.3877183 ],\n",
              "         [-0.2599411 , -0.26584947,  0.63453335, ...,  0.43149105,\n",
              "          -0.8482872 , -0.29509193],\n",
              "         [-0.1867908 , -0.52312934,  0.8774474 , ...,  0.62794495,\n",
              "          -0.8721332 , -0.5055715 ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              " array([[[ 0.11750754, -0.43039834, -0.57949626, ...,  0.07346938,\n",
              "           0.18857817,  0.5539588 ],\n",
              "         [ 0.84017414,  0.4734205 , -0.09907693, ...,  0.10374194,\n",
              "           0.5757628 , -0.64152396],\n",
              "         [ 2.4546769 ,  0.4128847 ,  0.59377545, ...,  0.50979567,\n",
              "          -0.6558333 , -0.08608054],\n",
              "         ...,\n",
              "         [ 0.05165103,  0.05327855,  1.4367328 , ...,  0.8579202 ,\n",
              "          -0.32088202, -0.4826304 ],\n",
              "         [ 0.04616095,  0.11812458,  1.2336874 , ...,  0.940198  ,\n",
              "          -0.3600971 , -0.5896819 ],\n",
              "         [-0.6276039 , -0.01092741,  1.329832  , ...,  0.9363191 ,\n",
              "          -0.5760924 , -0.5690378 ]],\n",
              " \n",
              "        [[-0.10351518, -0.6225212 , -0.6560621 , ..., -0.560577  ,\n",
              "           0.55460215,  0.9399966 ],\n",
              "         [-0.45538056,  0.35789207,  0.30344018, ..., -0.21253495,\n",
              "          -0.17191243, -0.43109703],\n",
              "         [ 0.08007044, -1.145143  ,  0.20265137, ...,  0.12236218,\n",
              "           0.43155172,  0.9192596 ],\n",
              "         ...,\n",
              "         [-0.0449166 , -0.34233668,  1.1671851 , ...,  0.09213936,\n",
              "          -0.55092716, -0.36176062],\n",
              "         [-0.25902268, -0.21327984,  1.132933  , ...,  0.17672426,\n",
              "          -0.59005165, -0.43005815],\n",
              "         [-0.03590022, -0.54764944,  1.1847672 , ...,  0.46901655,\n",
              "          -0.66071457, -0.5408556 ]],\n",
              " \n",
              "        [[ 0.21015292, -0.53323716, -0.35931832, ..., -0.44247878,\n",
              "           0.55539864,  0.5455353 ],\n",
              "         [-0.22448419, -0.04371542,  0.05248025, ..., -0.07033455,\n",
              "          -1.1390063 , -0.3169886 ],\n",
              "         [-0.46364963, -0.9376132 , -0.3097238 , ..., -0.667164  ,\n",
              "          -0.68484825,  0.7410452 ],\n",
              "         ...,\n",
              "         [-0.04520548, -0.16201852,  1.0897005 , ...,  0.28418007,\n",
              "          -0.6257055 , -0.3570416 ],\n",
              "         [-0.29586267,  0.01147822,  0.99756426, ...,  0.6197917 ,\n",
              "          -0.8768105 , -0.21027507],\n",
              "         [-0.17967047, -0.28215477,  1.1695707 , ...,  0.75774944,\n",
              "          -0.83998835, -0.43589982]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              " array([[[ 0.25688198, -0.29623502, -0.33276156, ...,  0.40788013,\n",
              "           0.62229353,  0.4158675 ],\n",
              "         [ 0.7373681 ,  0.32434288, -0.30461195, ...,  0.34615228,\n",
              "           0.84747326, -0.545353  ],\n",
              "         [ 1.989418  ,  0.84471416,  0.37647846, ...,  0.84692407,\n",
              "          -0.2403215 , -0.11678179],\n",
              "         ...,\n",
              "         [ 0.26925465,  0.04228792,  1.523375  , ...,  0.9452171 ,\n",
              "          -0.04222403, -0.4067264 ],\n",
              "         [ 0.25377133,  0.10208195,  1.3641794 , ...,  0.92601895,\n",
              "           0.00289947, -0.6996229 ],\n",
              "         [-0.6862095 , -0.26801568,  1.2181846 , ...,  0.8317719 ,\n",
              "          -0.16886547, -0.60233843]],\n",
              " \n",
              "        [[ 0.11075361, -0.24788654, -0.5061536 , ..., -0.7280706 ,\n",
              "           0.9904238 ,  1.0844005 ],\n",
              "         [-0.48110187,  0.06978938,  0.26367635, ..., -0.1544985 ,\n",
              "          -0.11487465, -0.44447747],\n",
              "         [ 0.44980887, -0.8439503 , -0.08609809, ..., -0.04559745,\n",
              "           0.88976115,  0.9924021 ],\n",
              "         ...,\n",
              "         [ 0.19304827, -0.335744  ,  1.4588796 , ...,  0.41265047,\n",
              "          -0.38216528, -0.41235313],\n",
              "         [-0.00731725, -0.23013794,  1.431122  , ...,  0.34898847,\n",
              "          -0.37664106, -0.47082037],\n",
              "         [ 0.1215515 , -0.5971342 ,  1.4525164 , ...,  0.58147484,\n",
              "          -0.41424036, -0.6260425 ]],\n",
              " \n",
              "        [[ 0.2480825 , -0.7642679 , -0.16242786, ..., -0.5805173 ,\n",
              "           0.8549879 ,  0.54348165],\n",
              "         [-0.06841208, -0.2533491 ,  0.21266732, ..., -0.04598415,\n",
              "          -0.7970142 , -0.24296404],\n",
              "         [-0.09896091, -0.89587855, -0.35401168, ..., -0.48450086,\n",
              "          -0.12560049,  1.1098713 ],\n",
              "         ...,\n",
              "         [ 0.26114127,  0.06931105,  1.1147991 , ...,  0.52809304,\n",
              "          -0.37150273, -0.3002253 ],\n",
              "         [ 0.03128614,  0.22589098,  1.0111787 , ...,  0.71106493,\n",
              "          -0.6070522 , -0.02722146],\n",
              "         [ 0.0884223 , -0.0885372 ,  1.2332042 , ...,  0.8504684 ,\n",
              "          -0.57350963, -0.2958338 ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              " array([[[ 0.37115717, -0.06972227, -0.54227036, ..., -0.30644393,\n",
              "           0.5562767 ,  0.5310393 ],\n",
              "         [ 0.6615938 ,  0.32918736, -0.8239473 , ...,  0.1065796 ,\n",
              "           0.78001827,  0.00815483],\n",
              "         [ 1.8165272 ,  0.82403654,  0.4292755 , ..., -0.06284936,\n",
              "           0.02823004,  0.1054003 ],\n",
              "         ...,\n",
              "         [ 0.3287594 ,  0.28949422,  1.5680209 , ...,  0.86959714,\n",
              "          -0.1810588 , -0.40243906],\n",
              "         [ 0.23216632,  0.2766165 ,  1.3453721 , ...,  0.82384473,\n",
              "          -0.06626583, -0.73623455],\n",
              "         [-0.7813622 , -0.17410682,  1.0637894 , ...,  0.34709677,\n",
              "          -0.40232855, -0.6124051 ]],\n",
              " \n",
              "        [[ 0.11041626, -0.16666597, -1.023568  , ..., -0.9312215 ,\n",
              "           0.7710269 ,  0.88211817],\n",
              "         [-0.2763698 , -0.22962566, -0.13827667, ..., -0.4226786 ,\n",
              "           0.07129981, -0.4982601 ],\n",
              "         [ 0.512131  , -0.6453898 , -0.08207624, ..., -0.36324888,\n",
              "           0.67943746,  1.1186641 ],\n",
              "         ...,\n",
              "         [ 0.4166924 , -0.37477264,  1.3102453 , ...,  0.39761183,\n",
              "          -0.54710543, -0.5560827 ],\n",
              "         [ 0.14312576, -0.22383893,  1.2680042 , ...,  0.3102912 ,\n",
              "          -0.565654  , -0.7139143 ],\n",
              "         [ 0.33570087, -0.6468445 ,  1.3351072 , ...,  0.58304703,\n",
              "          -0.5741804 , -0.8883595 ]],\n",
              " \n",
              "        [[ 0.45237982, -0.44949254, -0.48672754, ..., -0.8205674 ,\n",
              "           0.7899331 ,  0.8151901 ],\n",
              "         [-0.00636516, -0.1021232 , -0.06298264, ..., -0.13884467,\n",
              "          -0.6442579 , -0.3008192 ],\n",
              "         [ 0.10485519, -0.46292704, -0.24773975, ..., -0.56018823,\n",
              "           0.25398383,  1.0198225 ],\n",
              "         ...,\n",
              "         [ 0.5759312 ,  0.20366317,  1.1118479 , ...,  0.6711053 ,\n",
              "          -0.44126832, -0.17010754],\n",
              "         [ 0.0260252 ,  0.368774  ,  0.9405583 , ...,  0.89022714,\n",
              "          -0.6473642 , -0.00548776],\n",
              "         [ 0.17392085,  0.0302059 ,  1.1854585 , ...,  1.0100071 ,\n",
              "          -0.65498626, -0.303504  ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              " array([[[ 0.3619067 ,  0.11420095, -0.44243163, ..., -0.09247502,\n",
              "           0.36932778,  0.34458184],\n",
              "         [ 0.46611238,  0.49062252, -0.40511125, ..., -0.19810279,\n",
              "           0.5338974 , -0.01608093],\n",
              "         [ 1.2437588 ,  0.755193  ,  0.48486337, ...,  0.10265446,\n",
              "           0.19512045, -0.00424282],\n",
              "         ...,\n",
              "         [ 0.46197295,  0.5857698 ,  1.3556613 , ...,  1.0039514 ,\n",
              "          -0.1300819 , -0.12368909],\n",
              "         [ 0.37178725,  0.4039424 ,  1.1847714 , ...,  1.0458058 ,\n",
              "          -0.07963957, -0.6979543 ],\n",
              "         [-0.79566336, -0.2919956 ,  0.78247577, ...,  0.59399194,\n",
              "          -0.5184921 , -0.59793496]],\n",
              " \n",
              "        [[ 0.1320786 ,  0.34194154, -0.8142483 , ..., -0.91271555,\n",
              "           0.41032574,  0.74609625],\n",
              "         [-0.41876408, -0.46801907, -0.12544414, ..., -0.82211643,\n",
              "          -0.00493534, -0.4536142 ],\n",
              "         [ 0.45950264, -0.3390206 , -0.0689811 , ..., -0.49563357,\n",
              "           0.7144747 ,  1.1753601 ],\n",
              "         ...,\n",
              "         [ 0.49109745, -0.12698925,  1.118266  , ...,  0.15081052,\n",
              "          -0.40800154, -0.52856874],\n",
              "         [ 0.19997804, -0.05357146,  1.1576812 , ...,  0.151044  ,\n",
              "          -0.42617086, -0.73058283],\n",
              "         [ 0.37085924, -0.41010177,  1.2167788 , ...,  0.4697817 ,\n",
              "          -0.40912107, -0.8888293 ]],\n",
              " \n",
              "        [[ 0.56257015, -0.02209171, -0.45371947, ..., -0.6849206 ,\n",
              "           0.5420959 ,  0.6018052 ],\n",
              "         [ 0.21786334, -0.3282729 , -0.29218325, ..., -0.41277882,\n",
              "          -0.43263966, -0.06633221],\n",
              "         [-0.08892565, -0.38343245,  0.17677101, ..., -0.47247085,\n",
              "           0.49845722,  0.7831626 ],\n",
              "         ...,\n",
              "         [ 0.69359475,  0.12997109,  0.9650282 , ...,  0.38765657,\n",
              "          -0.24574111,  0.04957367],\n",
              "         [-0.08452289,  0.22367014,  0.64879507, ...,  0.63721794,\n",
              "          -0.5858827 ,  0.31199095],\n",
              "         [ 0.18900537,  0.04716267,  0.8969725 , ...,  0.8573067 ,\n",
              "          -0.5256681 , -0.02600895]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              " array([[[ 0.29073787, -0.07858679, -0.29300895, ..., -0.02634579,\n",
              "          -0.16627361,  0.2800286 ],\n",
              "         [ 0.3114689 ,  0.1869867 , -0.03118445, ..., -0.1064209 ,\n",
              "           0.57835895, -0.3022334 ],\n",
              "         [ 1.2707558 ,  0.61658037,  0.57367635, ...,  0.07933751,\n",
              "           0.5295036 , -0.14461829],\n",
              "         ...,\n",
              "         [ 0.28332585,  0.6842969 ,  1.0203656 , ...,  0.912894  ,\n",
              "          -0.27283838, -0.13033602],\n",
              "         [ 0.14960632,  0.45180726,  0.8271459 , ...,  1.0352308 ,\n",
              "          -0.29402387, -0.593316  ],\n",
              "         [-0.9951465 , -0.4189527 ,  0.59987193, ...,  1.0028323 ,\n",
              "          -0.8278476 , -0.5557138 ]],\n",
              " \n",
              "        [[ 0.05665045,  0.37678793, -0.5427443 , ..., -0.8201638 ,\n",
              "          -0.15513527,  0.46517828],\n",
              "         [-0.2903758 , -0.7604974 , -0.40327153, ..., -0.8423737 ,\n",
              "           0.09031782, -1.1882483 ],\n",
              "         [ 0.8012953 , -0.6129778 ,  0.15387325, ..., -0.50331575,\n",
              "           0.2685954 ,  0.6847399 ],\n",
              "         ...,\n",
              "         [ 0.1496959 , -0.10113976,  0.68330276, ..., -0.09372088,\n",
              "          -0.30933398, -0.65203786],\n",
              "         [-0.14634022, -0.05636591,  0.82245994, ..., -0.01338892,\n",
              "          -0.3665144 , -0.77034426],\n",
              "         [ 0.1019983 , -0.3332597 ,  0.87267745, ...,  0.21412495,\n",
              "          -0.4406492 , -0.9061376 ]],\n",
              " \n",
              "        [[ 0.5138907 , -0.21873371, -0.09274247, ..., -0.5333185 ,\n",
              "           0.06394905,  0.42349544],\n",
              "         [-0.39810127, -0.7028413 ,  0.36000532, ..., -0.80495054,\n",
              "          -0.55642056, -0.32774782],\n",
              "         [-0.00915758, -1.0733298 ,  0.44960383, ..., -0.57224905,\n",
              "           0.49369717,  0.30768302],\n",
              "         ...,\n",
              "         [ 0.54998994, -0.07460296,  0.6036818 , ...,  0.02691311,\n",
              "          -0.14225657, -0.02643674],\n",
              "         [-0.27978137,  0.02030603,  0.49319136, ...,  0.35643518,\n",
              "          -0.45913005,  0.35145846],\n",
              "         [ 0.08406898, -0.04419992,  0.6304246 , ...,  0.62554395,\n",
              "          -0.37572744, -0.0061361 ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              " array([[[ 0.38828415,  0.4348509 , -0.00305888, ..., -0.1152462 ,\n",
              "          -0.0870209 ,  0.19796641],\n",
              "         [ 0.4362004 ,  0.27804482, -0.12282149, ..., -0.46166548,\n",
              "           0.5111913 , -0.11277826],\n",
              "         [ 1.1603425 ,  0.8021936 ,  0.4968923 , ..., -0.05016576,\n",
              "           0.43671426,  0.16748482],\n",
              "         ...,\n",
              "         [ 0.56509167,  0.52560616,  0.9950653 , ...,  0.2358508 ,\n",
              "          -0.3336116 , -0.10615876],\n",
              "         [ 0.377955  ,  0.29136217,  0.86387366, ...,  0.37420455,\n",
              "          -0.37460577, -0.29910326],\n",
              "         [-0.5079772 , -0.39100027,  0.7629688 , ...,  0.4989516 ,\n",
              "          -0.5656434 , -0.5835227 ]],\n",
              " \n",
              "        [[ 0.32496786,  0.27099454,  0.07539525, ..., -0.524873  ,\n",
              "          -0.29960597,  0.420111  ],\n",
              "         [-0.21610235, -0.26233503, -0.80805135, ..., -0.78277177,\n",
              "           0.24213864, -0.7247552 ],\n",
              "         [ 0.4780231 , -0.6913348 ,  0.2643746 , ..., -0.72288924,\n",
              "           0.63886666,  0.9660993 ],\n",
              "         ...,\n",
              "         [ 0.09968758, -0.05260029,  0.6399418 , ..., -0.35871875,\n",
              "          -0.5016631 , -0.47143292],\n",
              "         [-0.15714145, -0.06077188,  0.7824112 , ..., -0.26149854,\n",
              "          -0.54947114, -0.57462454],\n",
              "         [ 0.04724874, -0.23972777,  0.81820714, ..., -0.12488895,\n",
              "          -0.6085112 , -0.64792913]],\n",
              " \n",
              "        [[ 0.47264776, -0.07413141,  0.3048028 , ..., -0.55095494,\n",
              "          -0.19143507,  0.1146422 ],\n",
              "         [-0.13916954, -0.7158463 , -0.1755997 , ..., -1.2559881 ,\n",
              "          -0.67485803,  0.07002946],\n",
              "         [-0.23890737, -0.9459681 ,  0.07326141, ..., -0.6354416 ,\n",
              "           0.22539018,  0.3898466 ],\n",
              "         ...,\n",
              "         [ 0.3720767 , -0.46739107,  0.34566745, ..., -0.67911786,\n",
              "          -0.29092163,  0.21775223],\n",
              "         [-0.14671004, -0.30063197,  0.27961084, ..., -0.25835016,\n",
              "          -0.5512219 ,  0.5328542 ],\n",
              "         [ 0.06021468, -0.33265442,  0.39901367, ...,  0.00423643,\n",
              "          -0.41640976,  0.2825313 ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
              " array([[[ 0.13989685,  0.30410853,  0.06352295, ..., -0.10268749,\n",
              "           0.22148427,  0.14977898],\n",
              "         [ 0.32137358,  0.29354602, -0.1408123 , ..., -0.20841433,\n",
              "           0.83567744,  0.20442402],\n",
              "         [ 1.1886755 ,  0.64992356,  0.6742487 , ...,  0.10617819,\n",
              "           0.41522282, -0.23921698],\n",
              "         ...,\n",
              "         [ 0.2002529 ,  0.27129635,  0.45000356, ...,  0.22973916,\n",
              "           0.02177444,  0.11564779],\n",
              "         [ 0.1203473 ,  0.17267032,  0.36960474, ...,  0.27761802,\n",
              "           0.02981692,  0.06090191],\n",
              "         [-0.23403423, -0.10138148,  0.3471217 , ...,  0.44735333,\n",
              "           0.04013262, -0.04988689]],\n",
              " \n",
              "        [[-0.02354308,  0.37282205, -0.09210153, ..., -0.44056374,\n",
              "           0.01131827,  0.3328247 ],\n",
              "         [-0.6194298 , -0.28675115, -0.72419006, ..., -0.38319874,\n",
              "           0.31782746, -0.2673164 ],\n",
              "         [ 0.22914922, -0.26078117, -0.25905174, ..., -0.38670355,\n",
              "           0.53242093,  0.7462712 ],\n",
              "         ...,\n",
              "         [ 0.03039839,  0.0043057 ,  0.3688119 , ..., -0.07569657,\n",
              "          -0.14002268, -0.04536304],\n",
              "         [-0.04000736, -0.0164677 ,  0.41010898, ..., -0.04975221,\n",
              "          -0.144483  , -0.07688889],\n",
              "         [ 0.02779413, -0.08786289,  0.40672043, ..., -0.01367262,\n",
              "          -0.15657677, -0.11102572]],\n",
              " \n",
              "        [[ 0.22074004,  0.01413434,  0.06443717, ..., -0.17645836,\n",
              "           0.19920635,  0.19690731],\n",
              "         [-0.14704725, -0.54524827, -0.10819175, ..., -0.8173358 ,\n",
              "           0.23186494,  0.19307591],\n",
              "         [-0.05048935, -0.71603614, -0.00176273, ..., -0.4684802 ,\n",
              "           0.04761183, -0.22504431],\n",
              "         ...,\n",
              "         [ 0.01195151, -0.22026901,  0.3875025 , ..., -0.32334277,\n",
              "           0.1346083 ,  0.17516093],\n",
              "         [-0.14100374, -0.20604482,  0.2578193 , ..., -0.16094595,\n",
              "           0.04925277,  0.24305022],\n",
              "         [-0.06052952, -0.22084403,  0.3242475 , ..., -0.06742799,\n",
              "           0.0959111 ,  0.17549217]]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HfxRuupmbqS",
        "outputId": "6a52d18e-44ea-4a3d-93a2-c9f34fd99414"
      },
      "source": [
        "# check if encoder output[-1] is same as pooled_output last embedding\n",
        "\n",
        "bert_results['encoder_outputs'][-1] == bert_results['sequence_output']"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 128, 768), dtype=bool, numpy=\n",
              "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]]])>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk8LklNlnhrI"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}